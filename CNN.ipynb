{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDLzKz1/ZTy+V+HelDpfy0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemre-data/DeepLearning_classification_skinlession_detection/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Nl0ZGjwggsqy",
        "outputId": "aaddc003-dde9-44e9-d43c-5f5eac06b8cb"
      },
      "source": [
        "!pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 8.7MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
            "Collecting numpy>=1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/42/560d269f604d3e186a57c21a363e77e199358d054884e61b73e405dd217c/numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 456kB/s \n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0 numpy-1.20.3 six-1.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FQQMEWHg4A0",
        "outputId": "30a0cbf9-38e8-46a7-b203-11fa9f6327bf"
      },
      "source": [
        "\n",
        "!pip uninstall keras-nightly\n",
        "!pip uninstall -y tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq4Ge2wng8oC",
        "outputId": "a01e55ff-41e0-48b5-edd5-a15bf187ad20"
      },
      "source": [
        "!pip install tensorflow_gpu==2.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_gpu==2.4.0 in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow_gpu==2.4.0) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (1.31.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow_gpu==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow_gpu==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow_gpu==2.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow_gpu==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow_gpu==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow_gpu==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow_gpu==2.4.0) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow_gpu==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow_gpu==2.4.0) (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow_gpu==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow_gpu==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow_gpu==2.4.0) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow_gpu==2.4.0) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SsHzMlLKiB_Y",
        "outputId": "58a06c5b-7545-402b-f335-860dd7473886"
      },
      "source": [
        "!pip install keras==2.4.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/19/9d8f1c86c09d05369da39b03d011cd689edef86c0e6b2777dbcedc49dfc6/Keras-2.4.0-py2.py3-none-any.whl (170kB)\n",
            "\r\u001b[K     |██                              | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.10.0)\n",
            "Collecting tensorflow>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/fd/993aa1333eb54d9f000863fe8ec61e41d12eb833dea51484c76c038718b5/tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.0) (1.15.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/e7/53bc896aa4e11a87aac10a625c676b3a3d57d1c8d9929e4809d31fa0b7d5/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.7.4.3)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.12.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/d1/f38a91d8724706427fe973a7dfa11e938cee98aa7196b03d870a25a08bab/grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (57.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (4.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.0 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.0 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.0 has requirement tensorflow-estimator<2.5.0,>=2.4.0rc0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-nightly, tensorflow-estimator, gast, grpcio, tensorflow, keras\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed gast-0.4.0 grpcio-1.34.1 keras-2.4.0 keras-nightly-2.5.0.dev2021032900 tensorflow-2.5.0 tensorflow-estimator-2.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV-pQAOqiCmp",
        "outputId": "45402fe8-5cce-4e39-f707-99b00e19cfc9"
      },
      "source": [
        "!pip install keras --user"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras) (2.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.34.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (0.36.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.12.1)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras) (2.5.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.2.0->keras) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.2.0->keras) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.2.0->keras) (4.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.2.0->keras) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.2.0->keras) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.2.0->keras) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.2.0->keras) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA2EowR8iFxb",
        "outputId": "cb3bb929-3b68-4530-e724-50e2c8eac927"
      },
      "source": [
        "#Keras preprosessing issue\n",
        "!pip uninstall keras-preprocessing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/Keras_Preprocessing-1.1.2.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras_preprocessing/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr9SNtrwiKj-",
        "outputId": "2418b5e2-4079-48af-e7e7-997f6ea8f298"
      },
      "source": [
        "!pip install git+https://github.com/keras-team/keras-preprocessing.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-y1tept2u\n",
            "  Running command git clone -q https://github.com/keras-team/keras-preprocessing.git /tmp/pip-req-build-y1tept2u\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.19.5)\n",
            "Building wheels for collected packages: Keras-Preprocessing\n",
            "  Building wheel for Keras-Preprocessing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-Preprocessing: filename=Keras_Preprocessing-1.1.2-cp37-none-any.whl size=43632 sha256=ee4614e411bf770dfbf581d8d79deb4643b7ded3815be19d96b2bc186de0836c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a3hp5_2u/wheels/03/a0/39/171f6040d36f36c71168dc69afa81334351b20955dc36ce932\n",
            "Successfully built Keras-Preprocessing\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.0 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.0 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.0 has requirement tensorflow-estimator<2.5.0,>=2.4.0rc0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpP70GymiOCV",
        "outputId": "f4846f3d-aa8d-4449-d977-3f61439f1a1d"
      },
      "source": [
        "!pip install np_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting np_utils\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/18/5704a782fd72727a9e63198fcc76fadb86975f45bcdf579c10f668329508/np_utils-0.5.12.1.tar.gz (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 20.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 20.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.5.12.1-cp37-none-any.whl size=57133 sha256=1ca3edbbff12409ed82b1a7c2623bbcb4c56176ce23ad8cf0657ccfc9005a1f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/4b/81/206efd0d01330a96f3aebe5021d2d5f0b264b7ade827c306ef\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.5.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2S8u3CydAIW",
        "outputId": "1d158ff8-0c52-404e-c9cf-aec2df0b4c15"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', 50)\n",
        "from scipy.spatial import cKDTree\n",
        "np.random.seed(123)\n",
        "from shapely.ops import nearest_points\n",
        "from math import *\n",
        "import urllib, os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob\n",
        "import cv2\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, Input, concatenate,ZeroPadding2D\n",
        "#from keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import argparse\n",
        "import locale\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
        "import itertools\n",
        "from tensorflow.keras import regularizers\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "#from keras.utils import plot_model\n",
        "import imgaug.augmenters as iaa\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.python.keras import backend as k\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, Masking, TimeDistributed\n",
        "from tensorflow. keras.utils import plot_model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.compat.v1.get_default_graph()\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnfP-deIthvZ",
        "outputId": "a31aff50-787a-48e5-a0a7-62afb4ccf18c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25A2bO-IdKzx"
      },
      "source": [
        "def create_cnn(width, height, depth, filters=(16, 32, 64,128,256), regularizer=None):\n",
        "\n",
        "    # Initialize the input shape and channel dimension, where the number of channels is the last dimension\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        " \n",
        "    # Define the model input\n",
        "    inputs = Input(shape=inputShape)\n",
        " \n",
        "    # Loop over the number of filters \n",
        "    for (i, f) in enumerate(filters):\n",
        "        # If this is the first CONV layer then set the input appropriately\n",
        "        if i == 0:\n",
        "            x = inputs\n",
        " \n",
        "        # Create loops of CONV => RELU => BN => POOL layers\n",
        "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = BatchNormalization(axis=chanDim)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        \n",
        "    # Final layers - flatten the volume, then Fully-Connected => RELU => BN => DROPOUT\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(16, kernel_regularizer=regularizer)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        " \n",
        "    # Apply another fully-connected layer, this one to match the number of nodes coming out of the MLP\n",
        "    x = Dense(3, kernel_regularizer=regularizer)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dense(3, activation=\"softmax\", name='last_layer')(x)\n",
        " \n",
        "    # Construct the CNN\n",
        "    model = Model(inputs, x)\n",
        " \n",
        "    # Return the CNN\n",
        "    return model  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0PVCOuKf5-F"
      },
      "source": [
        "def add_jpg(df):\n",
        "\n",
        "  name_images = []\n",
        "  for index, row in df.iterrows():\n",
        "    name_images.append(row['name']+\".jpg\")\n",
        "  df['name'] = name_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYwERNhNf1eM"
      },
      "source": [
        "df_train  =  pd.read_csv('/content/drive/My Drive/train/df_train')\n",
        "train_dir = '/content/drive/My Drive/train'\n",
        "test_dir = '/content/drive/My Drive/test'\n",
        "df_test =  pd.read_csv('/content/drive/My Drive/test/df_test')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x-W9coCzSkl"
      },
      "source": [
        "df_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_test.reset_index(drop=True, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA4wvIc1zdLE"
      },
      "source": [
        "df_train = df_train.loc[:, ~df_train.columns.str.contains('^Unnamed')]\n",
        "df_test = df_test.loc[:, ~df_test.columns.str.contains('^Unnamed')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGhR5ztojULU"
      },
      "source": [
        "add_jpg(df_train)\n",
        "add_jpg(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1I6w-rHgVah"
      },
      "source": [
        "df_train['meta.clinical.diagnosis'] = df_train['meta.clinical.diagnosis'].astype('str')\n",
        "df_test['meta.clinical.diagnosis'] = df_test['meta.clinical.diagnosis'].astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCCy8zaRgRWJ",
        "outputId": "c8a538b9-c2ca-4b7b-c4f3-bc528354925c"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "with tf.device('/device:GPU:0'):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1.0/255.0,\n",
        "      validation_split=0.20,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "      dataframe = df_train,\n",
        "      directory = train_dir,\n",
        "      x_col=\"name\",\n",
        "      y_col=\"meta.clinical.diagnosis\",\n",
        "      target_size=(512,512),\n",
        "      subset=\"training\",\n",
        "      batch_size=16,\n",
        "      seed =42,\n",
        "      shuffle=True,\n",
        "      class_mode=\"categorical\"\n",
        "    )\n",
        "\n",
        "    val_generator = train_datagen.flow_from_dataframe(\n",
        "      dataframe = df_train,\n",
        "      directory = train_dir,\n",
        "      x_col=\"name\",\n",
        "      y_col=\"meta.clinical.diagnosis\",\n",
        "      target_size=(512,512),\n",
        "      subset=\"validation\",\n",
        "      batch_size=16,\n",
        "      seed = 42,\n",
        "      shuffle=True,\n",
        "      class_mode=\"categorical\"\n",
        "    )  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2388 validated image filenames belonging to 3 classes.\n",
            "Found 597 validated image filenames belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEz3xRQbf0h9",
        "outputId": "bbf8f554-9ae0-4043-abf3-a64d62a6c717"
      },
      "source": [
        "cnn1 = create_cnn(512,512,3,regularizer=regularizers.l2(0.001))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIKpkV41fPG1",
        "outputId": "92cc63d0-112b-4ca8-ccbd-c1be4ec8e144"
      },
      "source": [
        "cnn1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 512, 512, 16)      448       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512, 512, 16)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512, 512, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 32)      4640      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 64)      18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                1048592   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 51        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "last_layer (Dense)           (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 1,443,311\n",
            "Trainable params: 1,442,287\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JN_4pLjTfAJm",
        "outputId": "26e6b925-b59d-4c0d-df27-01b3f11e9ff0"
      },
      "source": [
        "start = datetime.datetime.now()\n",
        "# compile the model \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "cnn1.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6) \n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/My Drive/Cnn_lr_0.001_16.h5\", verbose=1, save_best_only=True)\n",
        "\n",
        "model_history = cnn1.fit( train_generator, steps_per_epoch= train_generator.n // 16, epochs = 200, validation_data= val_generator, validation_steps= val_generator.n // 16, callbacks=[checkpointer, earlystopping])\n",
        "end = datetime.datetime.now()\n",
        "print(\"Time taken to run:\", end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 1.0911 - acc: 0.4979"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.98354, saving model to /content/drive/My Drive/Cnn_lr_0.001_16.h5\n",
            "149/149 [==============================] - 1109s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 1.0910 - acc: 0.4979 - val_loss: 0.9835 - val_acc: 0.7280\n",
            "Epoch 2/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.9763 - acc: 0.5599\n",
            "Epoch 00002: val_loss did not improve from 0.98354\n",
            "149/149 [==============================] - 1104s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.9763 - acc: 0.5599 - val_loss: 1.1178 - val_acc: 0.4054\n",
            "Epoch 3/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.9271 - acc: 0.5519\n",
            "Epoch 00003: val_loss improved from 0.98354 to 0.92490, saving model to /content/drive/My Drive/Cnn_lr_0.001_16.h5\n",
            "149/149 [==============================] - 1110s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.9271 - acc: 0.5519 - val_loss: 0.9249 - val_acc: 0.6453\n",
            "Epoch 4/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8748 - acc: 0.5902\n",
            "Epoch 00004: val_loss did not improve from 0.92490\n",
            "149/149 [==============================] - 1105s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8748 - acc: 0.5902 - val_loss: 1.0013 - val_acc: 0.5777\n",
            "Epoch 5/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8420 - acc: 0.5927\n",
            "Epoch 00005: val_loss improved from 0.92490 to 0.78371, saving model to /content/drive/My Drive/Cnn_lr_0.001_16.h5\n",
            "149/149 [==============================] - 1110s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8420 - acc: 0.5927 - val_loss: 0.7837 - val_acc: 0.6875\n",
            "Epoch 6/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8202 - acc: 0.6142\n",
            "Epoch 00006: val_loss did not improve from 0.78371\n",
            "149/149 [==============================] - 1115s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8202 - acc: 0.6142 - val_loss: 1.0179 - val_acc: 0.5355\n",
            "Epoch 7/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8221 - acc: 0.6244\n",
            "Epoch 00007: val_loss did not improve from 0.78371\n",
            "149/149 [==============================] - 1115s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8221 - acc: 0.6244 - val_loss: 3.1580 - val_acc: 0.2095\n",
            "Epoch 8/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8398 - acc: 0.6134\n",
            "Epoch 00008: val_loss did not improve from 0.78371\n",
            "149/149 [==============================] - 1120s 8s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8398 - acc: 0.6134 - val_loss: 0.8240 - val_acc: 0.6774\n",
            "Epoch 9/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8375 - acc: 0.6142\n",
            "Epoch 00009: val_loss did not improve from 0.78371\n",
            "149/149 [==============================] - 1112s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8375 - acc: 0.6142 - val_loss: 3.3301 - val_acc: 0.2601\n",
            "Epoch 10/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8079 - acc: 0.6294\n",
            "Epoch 00010: val_loss did not improve from 0.78371\n",
            "149/149 [==============================] - 1102s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8079 - acc: 0.6294 - val_loss: 1.4738 - val_acc: 0.3311\n",
            "Epoch 11/200\n",
            "149/149 [==============================] - ETA: 0s - batch: 74.0000 - size: 15.9195 - loss: 0.8087 - acc: 0.6273\n",
            "Epoch 00011: val_loss did not improve from 0.78371\n",
            "149/149 [==============================] - 1101s 7s/step - batch: 74.0000 - size: 15.9195 - loss: 0.8087 - acc: 0.6273 - val_loss: 2.0584 - val_acc: 0.1486\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-afc385568359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken to run:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdlA8I1v7F8v"
      },
      "source": [
        "def model_evaluation(model, history,  train_images, train_labels, test_features, test_images, test_labels, class_names=None, model_name=None):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a CNN with loss and accuracy plots, a confusion matrix and a classification report for the training and test sets.\n",
        "    \"\"\"\n",
        "    train_acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epch = range(1, len(train_acc) + 1)\n",
        "    plt.plot(epch, train_acc, 'g.', label='Training Accuracy')\n",
        "    plt.plot(epch, val_acc, 'g', label='Validation acc')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epch, train_loss, 'r.', label='Training loss')\n",
        "    plt.plot(epch, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    #results_test = model.evaluate([test_features, test_images], test_labels)\n",
        "    #print('Test Loss:', results_test[0])\n",
        "    #print('Test Accuracy:', results_test[1])\n",
        "    \n",
        "    y_train_pred = np.round(model.predict([train_features, train_images]))\n",
        "    y_pred = np.round(model.predict([test_features, test_images]))\n",
        "    \n",
        "    \n",
        "    print(classification_report(train_labels, y_train_pred,target_names=class_names))\n",
        "    print(classification_report(test_labels, y_pred,target_names=class_names))\n",
        "    confusion_matrix_plot(test_labels,y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q8YigIUdeF6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}